# Tools-AutomatedTextAnalizerAndExtractor
ğŸ¤–ğŸ’¬ A Python-based automation tool to download, extract, and organize training course PDFs from a list of URLs. Features include bulk downloading, title extraction using **PyMuPDF**, and structured storage of course metadata.

## *Locate your files:*

1. ğŸ“„**extract_cours_title.py**
2. ğŸ“„**extract_titles_from_links.py**
3. ğŸ“„**general.pdf**
4. ğŸ“„**links.txt**
5. ğŸ“„**output.txt**
6. ğŸ“„**titles.txt**

### ğŸ“– *Explanation of these files:* 

1. ğŸ“„**extract_cours_title.py:** here is where, given an specific PDF with the GCP Official Courses Format, the title of the course is extracted.
2. ğŸ“„**extract_titles_from_links.py:** this is where the automation happens. We used the file "links", where we upload the full list of links for all public and downloadlable PDFs, and we iterate it. One by one we analyse those links and extract the name of the course (the title).
3. ğŸ“„**general.pdf:** this is the pdf which is going to be used to extract the title by overwriting the content of the file. Instead of having dozens or hundreds of different pdfs we have only one which is going to be used to be analyzed.
4. ğŸ“„**links.txt:** the list of the links for the pdfs that we want to analyze.
5. ğŸ“„**output.txt:** this is a txt file which is goint to help the "extract_cours_title" process.
6. ğŸ“„**titles.txt:** the final result. The list of all the titles.

## ğŸ“ *Instructions:*
You must:
* âœ… Update the links.txt file with your own links.
* âœ… Clean the titles.txt file. Leave it in blank.
* âœ… Execute in your terminal: "python extract_titles_from_links.py"
* âœ… Wait for the results to be writen and completed.

That's it. ğŸ˜› How would you use this project?

## *Thanks for visiting*ğŸ§
##